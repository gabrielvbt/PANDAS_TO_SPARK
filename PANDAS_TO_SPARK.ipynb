{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"D:/spark-3.5.5-bin-hadoop3\"\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANDAS = pd.read_csv('COLUNA_.csv', sep=';')\n",
    "SPARK = spark.read.csv('COLUNA_.csv', sep=';', inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: os Displays abaixo são apenas para mostrar todos os prints no mesmo output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O PRINT DO DATAFRAME DO SPARK É TOTALMENTE DIFERENTE, PORÉM ELE POSSUI UMA FUNÇÃO ESPECIFICA PARA FICAR COMO O DF DO PANDAS:\n",
    "display(PANDAS)\n",
    "SPARK.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PANDAS.head(5))\n",
    "SPARK.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANDAS.rename(columns={'TESTE': 'COLUNA_1'}, inplace=True)\n",
    "SPARK.withColumRenamed('TESTE', 'COLUNA_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PANDAS.info)\n",
    "SPARK.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "PANDAS['COLUNA_2'] = PANDAS['COLUNA_2'].str.replace(',', '.')\n",
    "SPARK = SPARK.withColumn('COLUNA_2', f.regexp_replace('COLUNA_2', ',', '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANDAS['COLUNA_2'] = PANDAS['COLUNA_2'].astype(float)\n",
    "SPARK = SPARK.withColumn('COLUNA_2', SPARK['COLUNA_2'].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSUMINDO QUE O CAMPO DE DATA ESTA COMO INT/LONG, ETC EX 20200924 -> 24/09/2020\n",
    "PANDAS['COLUNA_3'] = pd.to_datetime(PANDAS['COLUNA_3'], dayfirst=True, errors='coerce')\n",
    "SPARK = SPARK.withColumn('COLUNA_3', f.to_date(SPARK.COLUNA_3.cast(StringType()), 'yyyMMdd'))#.withColum ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEMELHANTE AO SELECT SQL\n",
    "PANDAS[['COLUNA_1, COLUNA_2, COLUNA_3']]\n",
    "SPARK.select('*').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O DADO DEVE ESTAR EM FORMATO DATE\n",
    "PANDAS['COLUNA_4'] = PANDAS['COLUNA_3'].dt.year\n",
    "SPARK.select(f.year('COLUNA_3').alias('COLUNA_4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANDAS[(pd.isnull(PANDAS['COLUNA_3'])) | (pd.isnull(PANDAS['COLUNA_4']))]\n",
    "SPARK.select(f.when(f.isnull('COLUNA_3')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELE LEVA EM CONSIDERAÇÃO A TIPAGEM \n",
    "PANDAS.fillna(0)\n",
    "SPARK.na.fill(0)\n",
    "\n",
    "# PARA NONE:\n",
    "PANDAS.fillna('-')\n",
    "SPARK.na.fill('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
